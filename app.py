# ============================ –ò–ú–ü–û–†–¢–´ ============================
import os
import pickle
import matplotlib.pyplot as plt

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ (–æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏)
# from classes.video_analyzer_complex import VideoPipeline
from classes.video_anlyzer_without_faceraid import VideoPipeline
from classes.scene_enricher import SceneEnricher
from classes.openai import OpenAIThemer
from classes.scene_merge import UnifiedSceneMerger
from classes.audioanalyzer_and_transcriptor import AudioAnalyzer

# ============================ –ü–ê–†–ê–ú–ï–¢–†–´ ============================
VIDEO_PATH = "videos/Video_02.avi"           # –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
AUDIO_PATH = "temp/temp_audio.wav"           # –í—Ä–µ–º–µ–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª
OUTPUT_DIR = "output_files/"                 # –ü–∞–ø–∫–∞ –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
TEMP_DIR = "temp/"                           # –ü–∞–ø–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
CACHE_PATH = os.path.join(TEMP_DIR, "results.pkl")  # –ö–µ—à-—Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑–∞

MIN_SCENE_LENGTH = 2.0      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ü–µ–Ω—ã (—Å–µ–∫)
MAX_SCENE_LENGTH = 300.0    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ü–µ–Ω—ã (—Å–µ–∫)

# ============================ –í–ò–î–ï–û–ê–ù–ê–õ–ò–ó ============================

if os.path.exists(CACHE_PATH):
    print("üîÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –∫–µ—à–∞...")
    with open(CACHE_PATH, "rb") as f:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ü–µ–Ω—ã, –ª–∏—Ü–∞ –∏ —Ç—Ä–µ–∫–∏–Ω–≥-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        scenes, track_faces, tracking_frames = pickle.load(f)
else:
    print("üìΩ –ó–∞–ø—É—Å–∫ –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑–∞...")
    pipeline = VideoPipeline()
    scenes, track_faces, tracking_frames = pipeline.run(VIDEO_PATH, OUTPUT_DIR)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    os.makedirs(TEMP_DIR, exist_ok=True)
    with open(CACHE_PATH, "wb") as f:
        pickle.dump((scenes, track_faces, tracking_frames), f)

# ============================ –ê–£–î–ò–û–ê–ù–ê–õ–ò–ó ============================

print("üéß –ó–∞–ø—É—Å–∫ –∞—É–¥–∏–æ–∞–Ω–∞–ª–∏–∑–∞...")
splitter = AudioAnalyzer(
    video_path=VIDEO_PATH,
    output_dir=OUTPUT_DIR,
    whisper_model_size='small'
)
splitter.run(sensitivity=0.88, min_scene_duration=MIN_SCENE_LENGTH)

# –ö—Ä–∞—Ç–∫–∏–µ –∏ –ø–æ–ª–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Ä–µ—á–∏
segments_short = splitter.segments_short   # [{start, end, text}]
segments_full = splitter.segments          # Whisper-raw segments

# –†–∞—Å—á—ë—Ç –∞—É–¥–∏–æ—ç–Ω–µ—Ä–≥–∏–∏ –¥–ª—è —Å—Ü–µ–Ω
print("üìà –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ—ç–Ω–µ—Ä–≥–∏–∏...")
energy = splitter.detect_audio_activity(frame_duration=1.0)

# ============================ –û–ë–û–ì–ê–©–ï–ù–ò–ï –°–¶–ï–ù ============================

print("üß† –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å—Ü–µ–Ω –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç–∞...")
enricher = SceneEnricher(segments_full, energy)
# –ï—Å–ª–∏ –µ—Å—Ç—å `track_id_to_person`, –ø–µ—Ä–µ–¥–∞—Ç—å –µ–≥–æ –≤—Ç–æ—Ä—ã–º –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º
scenes_final = enricher.run(scenes)

# ============================ –¢–ï–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê ============================

print("üí¨ –ó–∞–ø—É—Å–∫ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —á–µ—Ä–µ–∑ LLM...")
themer = OpenAIThemer(
    api_key="",  # üîê –£–∫–∞–∂–∏ —Å–≤–æ–π OpenAI API –∫–ª—é—á
    base_url="https://api.proxyapi.ru/openai/v1"
)
themes = themer.get_themes(segments_short, audio_path=VIDEO_PATH)

# ============================ –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –°–¶–ï–ù ============================

print("üß© –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω...")
merger = UnifiedSceneMerger(VIDEO_PATH)
final_scenes = merger.run()

# ============================ –ì–û–¢–û–í–û ============================

print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω. –°—Ü–µ–Ω –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è: {len(final_scenes)}")
