from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import numpy as np

from utils.scene_tools import (
    enrich_scenes_with_characters,
    enrich_scenes_with_audio,
    group_semantic_scenes,
    cluster_scenes_with_time_windows,
    resolve_time_overlaps,
    clean_and_merge_short_scenes,
    save_scenes_report_to_json
)


class SceneEnricher:
    def __init__(self, segments, energy, device="cuda"):
        self.segments = segments
        self.energy = energy
        self.device = device

        print("üß† –ó–∞–≥—Ä—É–∑–∫–∞ sentence-transformer –º–æ–¥–µ–ª–∏...")
        self.sentence_model = SentenceTransformer("all-mpnet-base-v2", device=device)
        print("‚úÖ SentenceTransformer –≥–æ—Ç–æ–≤.")

    def enrich(self, scene_data, track_id_to_person=None):
        print("üé≠ –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å—Ü–µ–Ω...")

        # 1. –ö–æ–ø–∏—Ä—É–µ–º —Å—Ü–µ–Ω—ã –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è
        scenes = [dict(s) for s in scene_data]

        # 2. –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ track_id ‚Üí –∏–º—è)
        if track_id_to_person:
            print("üë§ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ —Å—Ü–µ–Ω—ã...")
            scenes = enrich_scenes_with_characters(scenes, track_id_to_person)

        # 3. –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ-—ç–Ω–µ—Ä–≥–∏—é
        print("üîä –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –∞—É–¥–∏–æ—ç–Ω–µ—Ä–≥–∏–∏...")
        scenes = enrich_scenes_with_audio(scenes, self.segments, self.energy)

        print(f"‚úÖ –û–±–æ–≥–∞—â–µ–Ω–æ —Å—Ü–µ–Ω: {len(scenes)}")
        return scenes

    def group(self, enriched_scenes, method="semantic"):
        print(f"üß© –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å—Ü–µ–Ω –º–µ—Ç–æ–¥–æ–º: {method}")

        if method == "semantic":
            scenes_grouped = group_semantic_scenes(enriched_scenes, self.sentence_model)
        elif method == "window":
            scenes_grouped = cluster_scenes_with_time_windows(enriched_scenes, self.sentence_model)
        else:
            raise ValueError(f"Unknown grouping method: {method}")

        print(f"‚úÖ –°—Ü–µ–Ω —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ: {len(scenes_grouped)}")
        return scenes_grouped

    def postprocess(self, scenes_grouped):
        print("üßº –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å—Ü–µ–Ω...")

        cleaned = resolve_time_overlaps(scenes_grouped)
        cleaned = clean_and_merge_short_scenes(cleaned)

        print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(cleaned)}")
        return cleaned

    def run(self, scene_data, track_id_to_person=None, print_report=True):
        print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏...")
        
        enriched = self.enrich(scene_data, track_id_to_person)
        grouped = self.group(enriched)
        cleaned = self.postprocess(grouped)

        if print_report:
            print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å—Ü–µ–Ω–∞–º...")
            save_scenes_report_to_json(cleaned)
            print("üìÅ JSON-–æ—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")

        print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ü–µ–Ω –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        return cleaned
