import os
import torch
import whisper
import openl3
import tensorflow_hub as hub
import tensorflow as tf
import shutil
import tarfile
import urllib.request
from sentence_transformers import SentenceTransformer
from ultralytics import YOLO
from transformers import CLIPProcessor, CLIPModel
from insightface.app import FaceAnalysis


def prepare_dirs():
    os.makedirs("models/whisper/small", exist_ok=True)
    os.makedirs("models/openl3", exist_ok=True)
    os.makedirs("models/yamnet", exist_ok=True)
    os.makedirs("models/sentence-transformers/all-mpnet-base-v2", exist_ok=True)
    os.makedirs("models/facenet", exist_ok=True)
    os.makedirs("models/clip", exist_ok=True)
    os.makedirs("models/yolo", exist_ok=True)
    os.makedirs("models/insightface", exist_ok=True)
    os.makedirs("models/torchreid", exist_ok=True)


def download_whisper_small():
    print(f"üîä –ó–∞–≥—Ä—É–∑–∫–∞ Whisper-small...")
    os.environ["WHISPER_CACHE"] = "models/whisper/small"
    _ = whisper.load_model("small")
    print("‚úÖ Whisper-small –∑–∞–≥—Ä—É–∂–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/whisper/small\n")


def download_openl3_model():
    print("üé∂ –ó–∞–≥—Ä—É–∑–∫–∞ OpenL3 –º–æ–¥–µ–ª–∏...")
    os.environ["KERAS_HOME"] = "models/openl3"
    model = openl3.models.load_audio_embedding_model(
        input_repr="mel256", content_type="music", embedding_size=6144
    )
    model.save("models/openl3/openl3_model.h5")
    print("‚úÖ OpenL3 —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/openl3/\n")


def download_yamnet_model():
    print("üîä –ó–∞–≥—Ä—É–∑–∫–∞ YAMNet –º–æ–¥–µ–ª–∏...")
    url = "https://tfhub.dev/google/yamnet/1?tf-hub-format=compressed"
    local_tar = "models/yamnet/yamnet.tar.gz"

    urllib.request.urlretrieve(url, local_tar)
    with tarfile.open(local_tar, "r:gz") as tar:
        tar.extractall(path="models/yamnet")

    os.remove(local_tar)
    print("‚úÖ YAMNet —Å–∫–∞—á–∞–Ω –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω –≤ models/yamnet/\n")


def download_sentence_transformer():
    print("üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformer: all-mpnet-base-v2...")
    model_path = "models/sentence-transformers/all-mpnet-base-v2"
    _ = SentenceTransformer("all-mpnet-base-v2", cache_folder=model_path)
    print(f"‚úÖ SentenceTransformer –∑–∞–≥—Ä—É–∂–µ–Ω –≤ {model_path}\n")

def download_yolo_model():
    print("üëÅ –ó–∞–≥—Ä—É–∑–∫–∞ YOLOv8n –º–æ–¥–µ–ª–∏...")
    model = YOLO("yolov8n.pt")
    model.save("models/yolo/yolov8n.pt")
    print("‚úÖ YOLOv8n –∑–∞–≥—Ä—É–∂–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/yolo/\n")


def download_clip_model():
    print("üé¨ –ó–∞–≥—Ä—É–∑–∫–∞ CLIP (ViT-B/32)...")
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    model.save_pretrained("models/clip")
    processor.save_pretrained("models/clip")
    print("‚úÖ CLIP (ViT-B/32) —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/clip/\n")


def download_insightface_model():
    print("üß† –ó–∞–≥—Ä—É–∑–∫–∞ InsightFace –º–æ–¥–µ–ª–∏ (buffalo_l)...")
    app = FaceAnalysis(name="buffalo_l")
    app.prepare(ctx_id=0 if torch.cuda.is_available() else -1)
    print("‚úÖ InsightFace 'buffalo_l' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–≤ ~/.insightface)\n")


def download_deepsort_torchreid():
    print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ DeepSort torchreid...")
    from deep_sort_realtime.embedder.embedder_pytorch import TorchReIDEmbedder
    _ = TorchReIDEmbedder(model_name='osnet_x1_0', device='cuda' if torch.cuda.is_available() else 'cpu')
    print("‚úÖ TorchReID embedder –∑–∞–≥—Ä—É–∂–µ–Ω\n")


if __name__ == "__main__":
    prepare_dirs()
    download_whisper_small()
    download_openl3_model()
    download_yamnet_model()
    download_sentence_transformer()
    download_yolo_model()
    download_clip_model()
    download_insightface_model()
    download_deepsort_torchreid()
    print("üéâ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ª–æ–∫–∞–ª—å–Ω–æ!")
