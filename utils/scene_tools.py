import os
import re
import json
import numpy as np
from sentence_transformers import util
from sklearn.cluster import DBSCAN

# ------------------------- –ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã -------------------------

def enrich_scenes_with_characters(scene_data, track_id_to_person):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ –∫–∞–∂–¥—É—é —Å—Ü–µ–Ω—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è track_id ‚Üí –∏–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞.
    """
    for scene in scene_data:
        scene['characters'] = list({
            track_id_to_person.get(tid)
            for tid in scene['track_ids']
            if tid in track_id_to_person
        })
    return scene_data


def get_identities(scene):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ 'characters' –∏–ª–∏ 'track_ids' –∏–∑ —Å—Ü–µ–Ω—ã.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å—Ü–µ–Ω–∞–º–∏.
    """
    return scene.get('characters', []) or scene.get('track_ids', [])


# ------------------------- –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ -------------------------

def normalize_text(t):
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é.
    """
    return re.sub(r'[^\w\s]', '', t.lower()).strip()


def get_text_score(a, b, sentenceTransformer):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏ —Å –ø–æ–º–æ—â—å—é SentenceTransformer.
    """
    a, b = normalize_text(a), normalize_text(b)
    if not a or not b:
        return 0.0
    a_embed = sentenceTransformer.encode(a, convert_to_tensor=True)
    b_embed = sentenceTransformer.encode(b, convert_to_tensor=True)
    return float(util.cos_sim(a_embed, b_embed)[0][0])


# ------------------------- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å—Ü–µ–Ω -------------------------

def jaccard_similarity(a, b):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ñ–∞–∫–∫–∞—Ä–∞ –º–µ–∂–¥—É –¥–≤—É–º—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞–º–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π.
    """
    set_a, set_b = set(a), set(b)
    intersection = set_a & set_b
    union = set_a | set_b
    return len(intersection) / len(union) if union else 0


def group_semantic_scenes(scene_data, sentenceTransformer, char_thresh=0.5, text_thresh=0.55, audio_thresh=0.02):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–æ—Å–µ–¥–Ω–∏–µ —Å—Ü–µ–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ö–æ–∂–∏ –ø–æ:
    - —Å–æ—Å—Ç–∞–≤—É –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π,
    - —Ç–µ–∫—Å—Ç—É (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏),
    - —É—Ä–æ–≤–Ω—é –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (RMS).
    """
    grouped = []
    buffer = [scene_data[0]]
    prev_text = scene_data[0]['transcript']

    for curr in scene_data[1:]:
        last = buffer[-1]

        char_score = jaccard_similarity(get_identities(curr), get_identities(last))
        text_score = get_text_score(prev_text, curr['transcript'], sentenceTransformer)
        audio_diff = abs(curr['avg_rms'] - last['avg_rms'])

        if char_score >= char_thresh and text_score >= text_thresh and audio_diff <= audio_thresh:
            buffer.append(curr)
            prev_text += " " + curr['transcript']
        else:
            grouped.append(_build_scene_from_buffer(buffer))
            buffer = [curr]
            prev_text = curr['transcript']

    if buffer:
        grouped.append(_build_scene_from_buffer(buffer))
    return grouped


def _build_scene_from_buffer(buffer):
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ü–µ–Ω—É –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö.
    """
    return {
        'start': buffer[0]['start'],
        'end': buffer[-1]['end'],
        'characters': sorted(set().union(*(get_identities(b) for b in buffer))),
        'transcript': " ".join(b['transcript'] for b in buffer),
        'avg_rms': float(np.mean([b['avg_rms'] for b in buffer]))
    }


def cluster_scenes_with_time_windows(scenes, sentenceTransformer, window_size=60, eps=0.45, min_samples=2):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é —Å—Ü–µ–Ω –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç DBSCAN –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º —Ç–µ–∫—Å—Ç–∞.
    """
    max_time = max(s['end'] for s in scenes)
    scenes_sorted = sorted(scenes, key=lambda x: x['start'])
    chapters = []
    start_window = 0

    while start_window < max_time:
        end_window = start_window + window_size
        window_scenes = [s for s in scenes_sorted if start_window <= s['start'] < end_window]
        if not window_scenes:
            start_window = end_window
            continue

        transcripts = [s['transcript'] for s in window_scenes]
        embeddings = sentenceTransformer.encode(transcripts, convert_to_tensor=False, normalize_embeddings=True)
        clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')
        labels = clustering.fit_predict(embeddings)

        clusters = {}
        for label, scene in zip(labels, window_scenes):
            label = f"scene_{scene['start']:.2f}" if label == -1 else label
            if label not in clusters:
                clusters[label] = {
                    "start": scene["start"],
                    "end": scene["end"],
                    "characters": set(scene["characters"]),
                    "transcripts": [scene["transcript"]],
                    "avg_rms": [scene["avg_rms"]],
                }
            else:
                clusters[label]["end"] = max(clusters[label]["end"], scene["end"])
                clusters[label]["characters"].update(scene["characters"])
                clusters[label]["transcripts"].append(scene["transcript"])
                clusters[label]["avg_rms"].append(scene["avg_rms"])

        for cluster in clusters.values():
            chapters.append({
                "start": cluster["start"],
                "end": cluster["end"],
                "characters": sorted(cluster["characters"]),
                "transcript": " ".join(cluster["transcripts"]),
                "avg_rms": float(np.mean(cluster["avg_rms"]))
            })

        start_window = end_window

    return sorted(chapters, key=lambda x: x['start'])


# ------------------------- –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è -------------------------

def enrich_scenes_with_audio(scenes, segments, energy, frame_duration=1.0):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –≤ —Å—Ü–µ–Ω—ã:
    - —Ç–µ–∫—Å—Ç –ø–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Ä–µ—á–∏,
    - —Å—Ä–µ–¥–Ω—é—é RMS-—ç–Ω–µ—Ä–≥–∏—é –ø–æ –∫–∞–¥—Ä–∞–º.
    """
    for scene in scenes:
        start, end = scene["start"], scene["end"]

        # –ü—Ä–∏–≤—è–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞
        scene_texts = [
            clip_text_to_scene(seg, start, end)
            for seg in segments
            if not (seg["end"] < start or seg["start"] > end)
        ]
        scene["transcript"] = " ".join(filter(None, scene_texts)).strip()

        # –†–∞—Å—á—ë—Ç —ç–Ω–µ—Ä–≥–∏–∏
        start_idx = max(0, int(start // frame_duration))
        end_idx = min(len(energy) - 1, int(end // frame_duration))
        scene_energy = energy[start_idx:end_idx + 1] if end_idx >= start_idx else []
        scene["avg_rms"] = float(np.mean(scene_energy)) if scene_energy else 0.0

    return scenes


def clean_and_merge_short_scenes(scenes, min_duration=2.0, min_words=3):
    """
    –£–¥–∞–ª—è–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –º–∞–ª–æ—Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ü–µ–Ω—ã, —Å–ª–∏–≤–∞—è –∏—Ö —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏.
    """
    cleaned = []
    buffer = None

    for scene in scenes:
        duration = scene["end"] - scene["start"]
        word_count = len(scene["transcript"].strip().split())

        if word_count < min_words or duration < 0.5:
            if cleaned:
                cleaned[-1] = merge_scene(cleaned[-1], scene)
            continue

        if duration < min_duration:
            if cleaned:
                cleaned[-1] = merge_scene(cleaned[-1], scene)
            else:
                buffer = scene
        else:
            cleaned.append(scene)

    if buffer:
        if cleaned:
            cleaned[-1] = merge_scene(cleaned[-1], buffer)
        else:
            cleaned.append(buffer)

    return cleaned


def merge_scene(a, b):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–≤–µ —Å—Ü–µ–Ω—ã –≤ –æ–¥–Ω—É.
    """
    return {
        "start": a["start"],
        "end": b["end"],
        "characters": sorted(set(a.get("characters", []) + b.get("characters", []))),
        "transcript": " ".join([a["transcript"], b["transcript"]]).strip(),
        "avg_rms": float(np.mean([a["avg_rms"], b["avg_rms"]]))
    }


def clip_text_to_scene(seg, start, end):
    """
    –í—ã—Ä–µ–∑–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞, –ø–æ–ø–∞–¥–∞—é—â—É—é –≤ —Å—Ü–µ–Ω—É.
    """
    seg_start, seg_end = seg["start"], seg["end"]
    overlap_start = max(start, seg_start)
    overlap_end = min(end, seg_end)
    overlap_dur = max(0.0, overlap_end - overlap_start)
    total_dur = seg_end - seg_start

    if overlap_dur == 0 or total_dur == 0:
        return ""

    words = seg["text"].strip().split()
    if len(words) <= 2:
        return seg["text"].strip()

    ratio = overlap_dur / total_dur
    count = max(1, int(len(words) * ratio))
    return " ".join(words[:count]) if overlap_start == seg_start else " ".join(words[-count:])


# ------------------------- –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –∏ —ç–∫—Å–ø–æ—Ä—Ç -------------------------

def resolve_time_overlaps(chapters):
    """
    –£–¥–∞–ª—è–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —Å—Ü–µ–Ω—ã, —Å–¥–≤–∏–≥–∞—è –Ω–∞—á–∞–ª–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –Ω–∞–ª–æ–∂–µ–Ω–∏–π.
    """
    chapters.sort(key=lambda x: x['start'])
    resolved = []
    prev_end = 0

    for ch in chapters:
        start = max(ch['start'], prev_end)
        end = ch['end']
        if start >= end:
            continue
        resolved.append({**ch, 'start': start, 'end': end})
        prev_end = end

    return resolved


def save_scenes_report_to_json(scenes):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—Ä–∞—Ç–∫–∏–π JSON-–æ—Ç—á–µ—Ç –æ —Å—Ü–µ–Ω–∞—Ö –≤ –ø–∞–ø–∫—É `reports/`.
    """
    os.makedirs("reports", exist_ok=True)
    base_name = "scenes_enriched"
    output_path = os.path.join("reports", f"{base_name}_report.json")

    scene_list = []
    for i, scene in enumerate(scenes):
        scene_info = {
            "scene_id": i + 1,
            "start_time_sec": round(scene["start"], 2),
            "end_time_sec": round(scene["end"], 2),
            "characters": scene.get("characters", []),
            "avg_rms": round(scene.get("avg_rms", 0.0), 4),
            "transcript": scene.get("transcript", "").strip()
        }
        scene_list.append(scene_info)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(scene_list, f, ensure_ascii=False, indent=4)

    print(f"‚úÖ JSON-–æ—Ç—á—ë—Ç –ø–æ —Å—Ü–µ–Ω–∞–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")


def print_scenes_formatted(scenes):
    """
    –ü–µ—á–∞—Ç–∞–µ—Ç —Å—Ü–µ–Ω—ã –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –∏ –¥–∏–∞–ª–æ–≥–∞–º–∏.
    """
    for i, scene in enumerate(scenes):
        print(f"\nüé¨ –°—Ü–µ–Ω–∞ {i + 1}")
        print(f"‚è± –í—Ä–µ–º—è: {scene['start']:.2f} ‚Äì {scene['end']:.2f} —Å–µ–∫")
        print(f"üßç –ü–µ—Ä—Å–æ–Ω–∞–∂–∏: {', '.join(scene['characters'])}")
        print(f"üîä –°—Ä–µ–¥–Ω—è—è –≥—Ä–æ–º–∫–æ—Å—Ç—å: {scene['avg_rms']:.4f}")
        print(f"üó£ –†–µ–ø–ª–∏–∫–∞:\n\"{scene['transcript'].strip()}\"")
        print("-" * 60)
